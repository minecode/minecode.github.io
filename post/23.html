<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Minecode</title><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="next-head-count" content="3"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/css/7e3d76f3b94b138f978c.css" as="style"/><link rel="stylesheet" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/css/7e3d76f3b94b138f978c.css" data-n-g=""/><noscript data-n-css=""></noscript><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/framework.bbb3e954997faabb7e25.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/4d394b6eac41034d52403a9c69bab475456b68cd.d652d981997954f1823c.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/main-a4e981f84634301fc825.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/pages/_app-ffad712006e2376eb55f.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/cb1608f2.bf396927f64ce5779777.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/7f039369aadd54df2b7485d9d62ad716e7ffd267.817674e39317854a8e95.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/122b2f7543d3b8cb2e0483e1b11b9e7f4c8a85b5.2959378f7e30a76c2452.js" as="script"/><link rel="preload" href="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/pages/post/%5Bid%5D-3ba8416640705b8635fe.js" as="script"/></head><body><div id="__next"><main><nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top"><div class="container"><a class="navbar-brand" href="/"><img src="/images/logo.png" width="30" height="30" alt=""/><span> Minecode</span></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button></div></nav><div class="content"><div style="box-sizing:border-box;position:relative;height:400px;width:100%;overflow:hidden"><div class="container-fluid" id="content" style="background-image:url(https://miro.medium.com/max/1400/1*SdvWc-pRqmZHDWXgYLOivg.png);background-size:cover;background-repeat:no-repeat;background-position:center;filter:blur(8px);height:100%;width:100%;position:absolute"></div><div class="container-fluid" style="background-color:rgb(0,0,0,0.5);color:white;font-weight:bold;z-index:2;height:100%;width:100%;text-align:center;position:relative"><div class="pricing-header px-3 py-3 mx-auto text-center" id="title"><h1 class="display-4" style="color:#fff;margin-top:5%">Set up Hadoop Cluster on VirtualBox machines running CentOS 7<br/></h1></div><div class="px-3 py-3 pb-md-4 mx-auto text-center"><div class="d-flex align-middle justify-content-center align-items-center"><div class="row"><div class="align-self-center p-2" id="infoPost"><p style="color:#fff;font-size:16px">Posted on <!-- -->April, 2020<!-- --> by<a class="mt-3 mb-4 btn btn-sm" href="https://github.com/tiagoslucas" target="_blank" rel="noopener noreferrer" style="color:#fff">tiagoslucas<!-- --> <img class="rounded-circle" src="https://avatars.githubusercontent.com/u/25772694?v=4" alt="Github" width="24" height="24"/></a></p></div></div></div></div></div></div><div class="container"><div class="pt-md-5 pb-md-4 mx-auto" id="post"><div><p><img alt="medium" src="https://miro.medium.com/max/1400/1*SdvWc-pRqmZHDWXgYLOivg.png"/></p><blockquote><p>In this tutorial I’m going to show you how to create your own Hadoop cluster with VirtualBox, using three CentOS virtual machines.</p></blockquote><h2>1<!-- -->.<!-- --> Setting up</h2><p>First, you’re gonna have to create a virtual machine on VirtualBox and install CentOS 7 on it. On our new virtual machine, the first thing we want to do is setup the network. For that, we’re going to use the command:</p><pre><code>nmtui</code></pre><p>It should open something like this:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*sXFRI9Acj0dAYgw9oC2dOg.png"/></p><p>Network Manager start screen</p><p>Let’s select “Edit a connection” and select one. It should have a name like “enp0s3”, at least that’s what I have on my VM.</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*aZObG9YbShaXorxGyJiN6A.png"/></p><p>You should set the IPv4 and IPv6 configurations to Automatic and select “Automatically connect” (select with Space). Then just press “OK”. If it went all fine you should now be able to ping “1.1.1.1”, Cloudflare’s DNS server. When you’re satisfied just press Ctrl + C to exit.</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*Qcsj3mSAZcAmhiqPNcpPxw.png"/></p><p>Now we’re going to install Java. For that you simply have to type:</p><pre><code>yum install java-1.8.0-openjdk-devel -y</code></pre><hr/><h2>2<!-- -->.<!-- --> Installing Hadoop</h2><p>It’s recommended that we create a “super user” to use hadoop, so we’ll do that by using the following commands:</p><pre><code>adduser hadoop  
passwd hadoop  
usermod -aG wheel hadoop</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*MZ0kOiC6mqTu8SfI8gLM3g.png"/></p><p>Creating the Super User “hadoop”</p><p>Next on we’re going to create a secure shell key and add it to “authorized keys” to enable an ssh connection to our machine. That can be done in the hadoop user by accessing it:</p><pre><code>su - hadoop</code></pre><p>And then just using the following commands:</p><pre><code>ssh-keygen -t rsa  
cat ~/.ssh/id\_rsa.pub &gt;&gt; ~/.ssh/authorized\_keys  
chmod 0600 ~/.ssh/authorized\_keys</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*acS0KDEbed5FVrtPzrNc6A.png"/></p><p>Generating and authorizing an ssh key</p><p>Now, on downloading the latest version of hadoop, we need to get the url from the website: <a href="https://hadoop.apache.org/releases.html">https://hadoop.apache.org/releases.html</a>. Once there, you select the latest binary and the following page will present you the URL. In my case it looks like this:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*cg69cQOow-9JB8p_QBI0Ew.png"/></p><p>Using the <em>curl</em> and <em>tar</em> commands we download hadoop from that URL and extract it:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*DUr668C-KUC3d-HmdYeepg.png"/></p><p>I’m going to rename my hadoop folder to simply “hadoop” (it’s a matter of issue):</p><pre><code>mv hadoop-3.1.2 hadoop</code></pre><p>Moving on we need to set some constants in our .bashrc file. That can be done by opening it with <em>vi</em>:</p><pre><code>vi ~/.bashrc</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*_tItWFpxwnCX_rvKquM07Q.png"/></p><p>Vi text editor</p><p>Inside <em>vi</em>, you just press “a” (the append shortcut) on your keyboard and add the following to the bottom of the file:</p><pre><code>**export** HADOOP\_HOME=**/**home**/**hadoop**/**hadoop  
**export** HADOOP\_INSTALL=$HADOOP\_HOME  
**export** HADOOP\_MAPRED\_HOME=$HADOOP\_HOME  
**export** HADOOP\_COMMON\_HOME=$HADOOP\_HOME  
**export** HADOOP\_HDFS\_HOME=$HADOOP\_HOME  
**export** YARN\_HOME=$HADOOP\_HOME  
**export** HADOOP\_COMMON\_LIB\_NATIVE\_DIR=$HADOOP\_HOME**/**lib**/**native  
**export** PATH=$PATH:$HADOOP\_HOME**/**sbin:$HADOOP\_HOME**/**bin</code></pre><blockquote><p>Now, note that in my case the folder is just called “hadoop”, but that may not be the case if you didn’t change it!</p></blockquote><p><img alt="medium" src="https://miro.medium.com/max/1400/1*dRmuyOgvutNR-lNS5sjrSA.png"/></p><p>Then just press Esc and write “:wq” (for write and quit). That should save the file. However, to change the current environment, we have to use the command:</p><pre><code>source ~/.bashrc</code></pre><p>To make sure everything is set right we can use:</p><pre><code>ls $HADOOP\_HOME</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*eLzatP494olkXGt22fFiWA.png"/></p><p>In case you didn’t get the same results as I did you should go back and review your <!-- -->~<!-- -->/.bashrc file.</p><hr/><h2>3<!-- -->.<!-- --> Setting up Hadoop</h2><p>Now that we have hadoop on our machine we should configure it. This is where we use the Java that we installed in the beginning of this tutorial.</p><p>First things first, we should navigate to the folder where all the configuration files should be by using:</p><pre><code>cd $HADOOP\_HOME/etc/hadoop</code></pre><p>The first file to edit is called “ hadoop-env.sh” and we’re going to use <em>vi</em> again:</p><pre><code>vi hadoop-env.sh</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*4Tyakyfl_3Mrb-eTDnvjAQ.png"/></p><p>We only need to add the line:</p><pre><code>export JAVA\_HOME=/usr/lib/jvm/java-1.8.0-openjdk</code></pre><p>It should be irrevelant where to put it, as long as it’s a new line. Then just write and quit <em>vi</em>. Finally, open and write for the following files:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*RP_pdHT4LiY_fGdFghqG1g.png"/></p><p>core-site.xml</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*bQ24fh7I-BT328dkq2OF2A.png"/></p><p>hdfs-site.xml</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*imibbW3qTRzAlgRjej7MwA.png"/></p><p>mapred-site.xml</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*Aj5lWFMK5J80Qsf0TbZVXQ.png"/></p><p>yarn-site.xml</p><p>With that done we return to our default directory with the command “cd”:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*ymuX6elvFKG1NnRcfOsHRA.png"/></p><p>“pwd” means “print working directory”</p><hr/><h2>4<!-- -->.<!-- --> Setting Up Multi-node</h2><p>To use a Multi-node setup we must define the nodes in our <em>hosts</em> file, which can be achieved using <em>vi</em> once more:</p><pre><code>vi /etc/hosts</code></pre><p>All we need to add are the nodes’ names and respective IP addresses. In my case I’m using three nodes, one  “master” and two “workers”:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*8Y0eVoZNZAXbOm4ObH5eEw.png"/></p><p>hosts file</p><p>Now we’re going to create those machines. To begin we have to clone the “master” machine twice:</p><p><img alt="medium" src="https://miro.medium.com/max/870/1*H-i3f647yEyrCCvkoLmMxA.png"/></p><p>Using the Right-Click, we select the “Clone” option</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*0fPvXtuGSdgiRLg4QCUWUg.png"/></p><p>After choosing the name and folder to the new machine, VirtualBox will start cloning</p><p>You should now have three virtual machines. For them to be able to communicate with each other, we’re going to open VirtualBox’s Network Settings:</p><p><img alt="medium" src="https://miro.medium.com/max/920/1*qPB5aGuC3qMwwI5Xl8fDpw.png"/></p><p>Using Right-Click again, we select “Settings”</p><p>On “Newtork”, we select “Adapter 2&quot;, enable and select Host-Only Adapter. Let’s set “Promiscuous Mode” to “Allow All” and be careful that the MAC Adresses are different from each other:</p><p><img alt="medium" src="https://miro.medium.com/max/1352/1*Jz7kT22mME9fDWy3Jv5Ckw.png"/></p><p>Each Virtual Machine should have a different hostname from the ones we defined in the <em>hosts</em> file. Log in with the hadoop account directly for this part.</p><p>The rest is simpler than what we’ve already done with <em>vi</em>:</p><pre><code>vi /etc/hostname</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*FkwHGnvPTL3drmyQpyc3jw.png"/></p><p>To further configure that, we have to use <em>nmtui</em> like at the start of this tutorial:</p><pre><code>nmtui</code></pre><p>In the new connection, “Wired Connection 1” in my case, we’ll simply set IPv4 to “Manual”, press “Show” and input the IP Address for the respective machine followed by “/24”. This is on my “master” VM:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*G-0u8FbPK9JF2NSASppnzA.png"/></p><p>Simply press “OK” and reboot. Rinse and repeat for each VM. We should now have a network between our machines:</p><p><img alt="medium" src="https://miro.medium.com/max/1400/1*4NlhytdbJTWclCTuO68K0w.png"/></p><p>Now let’s inform Hadoop about the existing nodes. On our “master” machine we should use the “hadoop” user to edit the <em>workers</em> file:</p><pre><code>vi $HADOOP\_HOME/etc/hadoop/workers</code></pre><p>In this file we need to write the machines that will do the work:</p><pre><code>master  
slave1  
slave2</code></pre><p><img alt="medium" src="https://miro.medium.com/max/1400/1*O6yUMgICJyrJNmVE7qV9jg.png"/></p><p>Finally, with all the machines on, we start our cluster by using the following commands on the “master” machine:</p><pre><code>$HADOOP\_HOME/etc/hadoop/start-dfs.sh  
$HADOOP\_HOME/etc/hadoop/start-yarn.sh</code></pre><p>But don’t take my word for granted, open one of your “worker” machines and use the <em>jps</em> command:</p><pre><code>jps</code></pre><p><img alt="medium" src="https://miro.medium.com/max/626/1*CP4SzVa3g5HLtQoBIkxrkw.png"/></p><p>If you see “NodeManager” and “DataNode” there, your cluster is up and running 🙂</p></div></div><div class="text-center"><a href="/tag/CentOS" class="m-1 btn btn-primary" style="background-color:#6ac421;border:none">CentOS</a><a href="/tag/Hadoop" class="m-1 btn btn-primary" style="background-color:#9e1e1c;border:none">Hadoop</a><a href="/tag/VirtualBox" class="m-1 btn btn-primary" style="background-color:#0583c1;border:none">VirtualBox</a></div><div class="mt-5 mb-5"></div><div class="row justify-content-center"><div class="col-4 row justify-content-center"><div class="align-self-center p-2">tiagoslucas<a class="mt-3 mb-4 btn btn-sm" href="https://github.com/tiagoslucas" target="_blank" rel="noopener noreferrer" style="color:#fff"><img class="rounded-circle" src="https://avatars.githubusercontent.com/u/25772694?v=4" alt="Github" width="24" height="24"/></a></div></div></div></div></div></main><footer class="py-5 bg-dark"><div class="container"><p class="m-0 text-center text-white">Copyright © Minecode 2020</p><p class="text-center mt-2"><a href="http://www.freepik.com">Designed by slidesgo, stories and macrovector / Freepik</a></p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23","repository_url":"https://api.github.com/repos/minecode/minecode.github.io","labels_url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23/labels{/name}","comments_url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23/comments","events_url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23/events","html_url":"https://github.com/minecode/minecode.github.io/issues/23","id":603584929,"node_id":"MDU6SXNzdWU2MDM1ODQ5Mjk=","number":23,"title":"[POST] Set up Hadoop Cluster on VirtualBox machines running CentOS 7","user":{"login":"tiagoslucas","id":25772694,"node_id":"MDQ6VXNlcjI1NzcyNjk0","avatar_url":"https://avatars.githubusercontent.com/u/25772694?v=4","gravatar_id":"","url":"https://api.github.com/users/tiagoslucas","html_url":"https://github.com/tiagoslucas","followers_url":"https://api.github.com/users/tiagoslucas/followers","following_url":"https://api.github.com/users/tiagoslucas/following{/other_user}","gists_url":"https://api.github.com/users/tiagoslucas/gists{/gist_id}","starred_url":"https://api.github.com/users/tiagoslucas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tiagoslucas/subscriptions","organizations_url":"https://api.github.com/users/tiagoslucas/orgs","repos_url":"https://api.github.com/users/tiagoslucas/repos","events_url":"https://api.github.com/users/tiagoslucas/events{/privacy}","received_events_url":"https://api.github.com/users/tiagoslucas/received_events","type":"User","site_admin":false},"labels":[{"id":2002693892,"node_id":"MDU6TGFiZWwyMDAyNjkzODky","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/CentOS","name":"CentOS","color":"6ac421","default":false,"description":""},{"id":2002694529,"node_id":"MDU6TGFiZWwyMDAyNjk0NTI5","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/Hadoop","name":"Hadoop","color":"9e1e1c","default":false,"description":""},{"id":2002694225,"node_id":"MDU6TGFiZWwyMDAyNjk0MjI1","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/VirtualBox","name":"VirtualBox","color":"0583c1","default":false,"description":""},{"id":1923405712,"node_id":"MDU6TGFiZWwxOTIzNDA1NzEy","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/post","name":"post","color":"2dc64e","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-04-20T22:52:01Z","updated_at":"2020-04-21T09:20:03Z","closed_at":"2020-04-20T23:21:29Z","author_association":"NONE","active_lock_reason":null,"body":"![medium](https://miro.medium.com/max/1400/1*SdvWc-pRqmZHDWXgYLOivg.png)\r\n\r\n\u003e In this tutorial I’m going to show you how to create your own Hadoop cluster with VirtualBox, using three CentOS virtual machines.\r\n\r\n1\\. Setting up\r\n--------------\r\n\r\nFirst, you’re gonna have to create a virtual machine on VirtualBox and install CentOS 7 on it. On our new virtual machine, the first thing we want to do is setup the network. For that, we’re going to use the command:\r\n\r\n```\r\nnmtui\r\n```\r\n\r\nIt should open something like this:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*sXFRI9Acj0dAYgw9oC2dOg.png)\r\n\r\nNetwork Manager start screen\r\n\r\nLet’s select “Edit a connection” and select one. It should have a name like “enp0s3”, at least that’s what I have on my VM.\r\n\r\n![medium](https://miro.medium.com/max/1400/1*aZObG9YbShaXorxGyJiN6A.png)\r\n\r\nYou should set the IPv4 and IPv6 configurations to Automatic and select “Automatically connect” (select with Space). Then just press “OK”. If it went all fine you should now be able to ping “1.1.1.1”, Cloudflare’s DNS server. When you’re satisfied just press Ctrl + C to exit.\r\n\r\n![medium](https://miro.medium.com/max/1400/1*Qcsj3mSAZcAmhiqPNcpPxw.png)\r\n\r\nNow we’re going to install Java. For that you simply have to type:\r\n\r\n```\r\nyum install java-1.8.0-openjdk-devel -y\r\n```\r\n\r\n* * *\r\n\r\n2\\. Installing Hadoop\r\n---------------------\r\n\r\nIt’s recommended that we create a “super user” to use hadoop, so we’ll do that by using the following commands:\r\n\r\n```\r\nadduser hadoop  \r\npasswd hadoop  \r\nusermod -aG wheel hadoop\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*MZ0kOiC6mqTu8SfI8gLM3g.png)\r\n\r\nCreating the Super User “hadoop”\r\n\r\nNext on we’re going to create a secure shell key and add it to “authorized keys” to enable an ssh connection to our machine. That can be done in the hadoop user by accessing it:\r\n\r\n```\r\nsu - hadoop\r\n```\r\n\r\nAnd then just using the following commands:\r\n\r\n```\r\nssh-keygen -t rsa  \r\ncat ~/.ssh/id\\_rsa.pub \u003e\u003e ~/.ssh/authorized\\_keys  \r\nchmod 0600 ~/.ssh/authorized\\_keys\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*acS0KDEbed5FVrtPzrNc6A.png)\r\n\r\nGenerating and authorizing an ssh key\r\n\r\nNow, on downloading the latest version of hadoop, we need to get the url from the website: [https://hadoop.apache.org/releases.html](https://hadoop.apache.org/releases.html). Once there, you select the latest binary and the following page will present you the URL. In my case it looks like this:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*cg69cQOow-9JB8p_QBI0Ew.png)\r\n\r\nUsing the _curl_ and _tar_ commands we download hadoop from that URL and extract it:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*DUr668C-KUC3d-HmdYeepg.png)\r\n\r\nI’m going to rename my hadoop folder to simply “hadoop” (it’s a matter of issue):\r\n\r\n```\r\nmv hadoop-3.1.2 hadoop\r\n```\r\n\r\nMoving on we need to set some constants in our .bashrc file. That can be done by opening it with _vi_:\r\n\r\n```\r\nvi ~/.bashrc\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*_tItWFpxwnCX_rvKquM07Q.png)\r\n\r\nVi text editor\r\n\r\nInside _vi_, you just press “a” (the append shortcut) on your keyboard and add the following to the bottom of the file:\r\n\r\n```\r\n**export** HADOOP\\_HOME=**/**home**/**hadoop**/**hadoop  \r\n**export** HADOOP\\_INSTALL=$HADOOP\\_HOME  \r\n**export** HADOOP\\_MAPRED\\_HOME=$HADOOP\\_HOME  \r\n**export** HADOOP\\_COMMON\\_HOME=$HADOOP\\_HOME  \r\n**export** HADOOP\\_HDFS\\_HOME=$HADOOP\\_HOME  \r\n**export** YARN\\_HOME=$HADOOP\\_HOME  \r\n**export** HADOOP\\_COMMON\\_LIB\\_NATIVE\\_DIR=$HADOOP\\_HOME**/**lib**/**native  \r\n**export** PATH=$PATH:$HADOOP\\_HOME**/**sbin:$HADOOP\\_HOME**/**bin\r\n```\r\n\r\n\u003e Now, note that in my case the folder is just called “hadoop”, but that may not be the case if you didn’t change it!\r\n\r\n![medium](https://miro.medium.com/max/1400/1*dRmuyOgvutNR-lNS5sjrSA.png)\r\n\r\nThen just press Esc and write “:wq” (for write and quit). That should save the file. However, to change the current environment, we have to use the command:\r\n\r\n```\r\nsource ~/.bashrc\r\n```\r\n\r\nTo make sure everything is set right we can use:\r\n\r\n```\r\nls $HADOOP\\_HOME\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*eLzatP494olkXGt22fFiWA.png)\r\n\r\nIn case you didn’t get the same results as I did you should go back and review your \\~/.bashrc file.\r\n\r\n* * *\r\n\r\n3\\. Setting up Hadoop\r\n---------------------\r\n\r\nNow that we have hadoop on our machine we should configure it. This is where we use the Java that we installed in the beginning of this tutorial.\r\n\r\nFirst things first, we should navigate to the folder where all the configuration files should be by using:\r\n\r\n```\r\ncd $HADOOP\\_HOME/etc/hadoop\r\n```\r\n\r\nThe first file to edit is called “ hadoop-env.sh” and we’re going to use _vi_ again:\r\n\r\n```\r\nvi hadoop-env.sh\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*4Tyakyfl_3Mrb-eTDnvjAQ.png)\r\n\r\nWe only need to add the line:\r\n\r\n```\r\nexport JAVA\\_HOME=/usr/lib/jvm/java-1.8.0-openjdk\r\n```\r\n\r\nIt should be irrevelant where to put it, as long as it’s a new line. Then just write and quit _vi_. Finally, open and write for the following files:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*RP_pdHT4LiY_fGdFghqG1g.png)\r\n\r\ncore-site.xml\r\n\r\n![medium](https://miro.medium.com/max/1400/1*bQ24fh7I-BT328dkq2OF2A.png)\r\n\r\nhdfs-site.xml\r\n\r\n![medium](https://miro.medium.com/max/1400/1*imibbW3qTRzAlgRjej7MwA.png)\r\n\r\nmapred-site.xml\r\n\r\n![medium](https://miro.medium.com/max/1400/1*Aj5lWFMK5J80Qsf0TbZVXQ.png)\r\n\r\nyarn-site.xml\r\n\r\nWith that done we return to our default directory with the command “cd”:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*ymuX6elvFKG1NnRcfOsHRA.png)\r\n\r\n“pwd” means “print working directory”\r\n\r\n* * *\r\n\r\n4\\. Setting Up Multi-node\r\n-------------------------\r\n\r\nTo use a Multi-node setup we must define the nodes in our _hosts_ file, which can be achieved using _vi_ once more:\r\n\r\n```\r\nvi /etc/hosts\r\n```\r\n\r\nAll we need to add are the nodes’ names and respective IP addresses. In my case I’m using three nodes, one  “master” and two “workers”:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*8Y0eVoZNZAXbOm4ObH5eEw.png)\r\n\r\nhosts file\r\n\r\nNow we’re going to create those machines. To begin we have to clone the “master” machine twice:\r\n\r\n![medium](https://miro.medium.com/max/870/1*H-i3f647yEyrCCvkoLmMxA.png)\r\n\r\nUsing the Right-Click, we select the “Clone” option\r\n\r\n![medium](https://miro.medium.com/max/1400/1*0fPvXtuGSdgiRLg4QCUWUg.png)\r\n\r\nAfter choosing the name and folder to the new machine, VirtualBox will start cloning\r\n\r\nYou should now have three virtual machines. For them to be able to communicate with each other, we’re going to open VirtualBox’s Network Settings:\r\n\r\n![medium](https://miro.medium.com/max/920/1*qPB5aGuC3qMwwI5Xl8fDpw.png)\r\n\r\nUsing Right-Click again, we select “Settings”\r\n\r\nOn “Newtork”, we select “Adapter 2\", enable and select Host-Only Adapter. Let’s set “Promiscuous Mode” to “Allow All” and be careful that the MAC Adresses are different from each other:\r\n\r\n![medium](https://miro.medium.com/max/1352/1*Jz7kT22mME9fDWy3Jv5Ckw.png)\r\n\r\nEach Virtual Machine should have a different hostname from the ones we defined in the _hosts_ file. Log in with the hadoop account directly for this part.\r\n\r\nThe rest is simpler than what we’ve already done with _vi_:\r\n\r\n```\r\nvi /etc/hostname\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*FkwHGnvPTL3drmyQpyc3jw.png)\r\n\r\nTo further configure that, we have to use _nmtui_ like at the start of this tutorial:\r\n\r\n```\r\nnmtui\r\n```\r\n\r\nIn the new connection, “Wired Connection 1” in my case, we’ll simply set IPv4 to “Manual”, press “Show” and input the IP Address for the respective machine followed by “/24”. This is on my “master” VM:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*G-0u8FbPK9JF2NSASppnzA.png)\r\n\r\nSimply press “OK” and reboot. Rinse and repeat for each VM. We should now have a network between our machines:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*4NlhytdbJTWclCTuO68K0w.png)\r\n\r\nNow let’s inform Hadoop about the existing nodes. On our “master” machine we should use the “hadoop” user to edit the _workers_ file:\r\n\r\n```\r\nvi $HADOOP\\_HOME/etc/hadoop/workers\r\n```\r\n\r\nIn this file we need to write the machines that will do the work:\r\n\r\n```\r\nmaster  \r\nslave1  \r\nslave2\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*O6yUMgICJyrJNmVE7qV9jg.png)\r\n\r\nFinally, with all the machines on, we start our cluster by using the following commands on the “master” machine:\r\n\r\n```\r\n$HADOOP\\_HOME/etc/hadoop/start-dfs.sh  \r\n$HADOOP\\_HOME/etc/hadoop/start-yarn.sh\r\n```\r\n\r\nBut don’t take my word for granted, open one of your “worker” machines and use the _jps_ command:\r\n\r\n```\r\njps\r\n```\r\n\r\n![medium](https://miro.medium.com/max/626/1*CP4SzVa3g5HLtQoBIkxrkw.png)\r\n\r\nIf you see “NodeManager” and “DataNode” there, your cluster is up and running 🙂\r\n","closed_by":{"login":"cfchenr","id":17366849,"node_id":"MDQ6VXNlcjE3MzY2ODQ5","avatar_url":"https://avatars.githubusercontent.com/u/17366849?v=4","gravatar_id":"","url":"https://api.github.com/users/cfchenr","html_url":"https://github.com/cfchenr","followers_url":"https://api.github.com/users/cfchenr/followers","following_url":"https://api.github.com/users/cfchenr/following{/other_user}","gists_url":"https://api.github.com/users/cfchenr/gists{/gist_id}","starred_url":"https://api.github.com/users/cfchenr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cfchenr/subscriptions","organizations_url":"https://api.github.com/users/cfchenr/orgs","repos_url":"https://api.github.com/users/cfchenr/repos","events_url":"https://api.github.com/users/cfchenr/events{/privacy}","received_events_url":"https://api.github.com/users/cfchenr/received_events","type":"User","site_admin":false},"performed_via_github_app":null},"relatedPosts":[]},"__N_SSG":true},"page":"/post/[id]","query":{"id":"23"},"buildId":"u8zW19TnfOuce_n6hjyVG","assetPrefix":"https://cdn.statically.io/gh/minecode/minecode.github.io/master","isFallback":false,"gsp":true}</script><script nomodule="" src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/polyfills-28654a8145d7603786fc.js"></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/framework.bbb3e954997faabb7e25.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/4d394b6eac41034d52403a9c69bab475456b68cd.d652d981997954f1823c.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/main-a4e981f84634301fc825.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/pages/_app-ffad712006e2376eb55f.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/cb1608f2.bf396927f64ce5779777.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/7f039369aadd54df2b7485d9d62ad716e7ffd267.817674e39317854a8e95.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/122b2f7543d3b8cb2e0483e1b11b9e7f4c8a85b5.2959378f7e30a76c2452.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/chunks/pages/post/%5Bid%5D-3ba8416640705b8635fe.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/u8zW19TnfOuce_n6hjyVG/_buildManifest.js" async=""></script><script src="https://cdn.statically.io/gh/minecode/minecode.github.io/master/_next/static/u8zW19TnfOuce_n6hjyVG/_ssgManifest.js" async=""></script></body></html>