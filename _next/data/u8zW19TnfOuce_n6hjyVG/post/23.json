{"pageProps":{"post":{"url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23","repository_url":"https://api.github.com/repos/minecode/minecode.github.io","labels_url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23/labels{/name}","comments_url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23/comments","events_url":"https://api.github.com/repos/minecode/minecode.github.io/issues/23/events","html_url":"https://github.com/minecode/minecode.github.io/issues/23","id":603584929,"node_id":"MDU6SXNzdWU2MDM1ODQ5Mjk=","number":23,"title":"[POST] Set up Hadoop Cluster on VirtualBox machines running CentOS 7","user":{"login":"tiagoslucas","id":25772694,"node_id":"MDQ6VXNlcjI1NzcyNjk0","avatar_url":"https://avatars.githubusercontent.com/u/25772694?v=4","gravatar_id":"","url":"https://api.github.com/users/tiagoslucas","html_url":"https://github.com/tiagoslucas","followers_url":"https://api.github.com/users/tiagoslucas/followers","following_url":"https://api.github.com/users/tiagoslucas/following{/other_user}","gists_url":"https://api.github.com/users/tiagoslucas/gists{/gist_id}","starred_url":"https://api.github.com/users/tiagoslucas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tiagoslucas/subscriptions","organizations_url":"https://api.github.com/users/tiagoslucas/orgs","repos_url":"https://api.github.com/users/tiagoslucas/repos","events_url":"https://api.github.com/users/tiagoslucas/events{/privacy}","received_events_url":"https://api.github.com/users/tiagoslucas/received_events","type":"User","site_admin":false},"labels":[{"id":2002693892,"node_id":"MDU6TGFiZWwyMDAyNjkzODky","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/CentOS","name":"CentOS","color":"6ac421","default":false,"description":""},{"id":2002694529,"node_id":"MDU6TGFiZWwyMDAyNjk0NTI5","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/Hadoop","name":"Hadoop","color":"9e1e1c","default":false,"description":""},{"id":2002694225,"node_id":"MDU6TGFiZWwyMDAyNjk0MjI1","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/VirtualBox","name":"VirtualBox","color":"0583c1","default":false,"description":""},{"id":1923405712,"node_id":"MDU6TGFiZWwxOTIzNDA1NzEy","url":"https://api.github.com/repos/minecode/minecode.github.io/labels/post","name":"post","color":"2dc64e","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-04-20T22:52:01Z","updated_at":"2020-04-21T09:20:03Z","closed_at":"2020-04-20T23:21:29Z","author_association":"NONE","active_lock_reason":null,"body":"![medium](https://miro.medium.com/max/1400/1*SdvWc-pRqmZHDWXgYLOivg.png)\r\n\r\n> In this tutorial Iâ€™m going to show you how to create your own Hadoop cluster with VirtualBox, using three CentOS virtual machines.\r\n\r\n1\\. Setting up\r\n--------------\r\n\r\nFirst, youâ€™re gonna have to create a virtual machine on VirtualBox and install CentOS 7 on it. On our new virtual machine, the first thing we want to do is setup the network. For that, weâ€™re going to use the command:\r\n\r\n```\r\nnmtui\r\n```\r\n\r\nIt should open something like this:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*sXFRI9Acj0dAYgw9oC2dOg.png)\r\n\r\nNetwork Manager start screen\r\n\r\nLetâ€™s select â€œEdit a connectionâ€ and select one. It should have a name like â€œenp0s3â€, at least thatâ€™s what I have on my VM.\r\n\r\n![medium](https://miro.medium.com/max/1400/1*aZObG9YbShaXorxGyJiN6A.png)\r\n\r\nYou should set the IPv4 and IPv6 configurations to Automatic and select â€œAutomatically connectâ€ (select with Space). Then just press â€œOKâ€. If it went all fine you should now be able to ping â€œ1.1.1.1â€, Cloudflareâ€™s DNS server. When youâ€™re satisfied just press Ctrl + C to exit.\r\n\r\n![medium](https://miro.medium.com/max/1400/1*Qcsj3mSAZcAmhiqPNcpPxw.png)\r\n\r\nNow weâ€™re going to install Java. For that you simply have to type:\r\n\r\n```\r\nyum install java-1.8.0-openjdk-devel -y\r\n```\r\n\r\n* * *\r\n\r\n2\\. Installing Hadoop\r\n---------------------\r\n\r\nItâ€™s recommended that we create a â€œsuper userâ€ to use hadoop, so weâ€™ll do that by using the following commands:\r\n\r\n```\r\nadduser hadoop  \r\npasswd hadoop  \r\nusermod -aG wheel hadoop\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*MZ0kOiC6mqTu8SfI8gLM3g.png)\r\n\r\nCreating the Super User â€œhadoopâ€\r\n\r\nNext on weâ€™re going to create a secure shell key and add it to â€œauthorized keysâ€ to enable an ssh connection to our machine. That can be done in the hadoop user by accessing it:\r\n\r\n```\r\nsu - hadoop\r\n```\r\n\r\nAnd then just using the following commands:\r\n\r\n```\r\nssh-keygen -t rsa  \r\ncat ~/.ssh/id\\_rsa.pub >> ~/.ssh/authorized\\_keys  \r\nchmod 0600 ~/.ssh/authorized\\_keys\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*acS0KDEbed5FVrtPzrNc6A.png)\r\n\r\nGenerating and authorizing an ssh key\r\n\r\nNow, on downloading the latest version of hadoop, we need to get the url from the website: [https://hadoop.apache.org/releases.html](https://hadoop.apache.org/releases.html). Once there, you select the latest binary and the following page will present you the URL. In my case it looks like this:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*cg69cQOow-9JB8p_QBI0Ew.png)\r\n\r\nUsing the _curl_ and _tar_ commands we download hadoop from that URL and extract it:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*DUr668C-KUC3d-HmdYeepg.png)\r\n\r\nIâ€™m going to rename my hadoop folder to simply â€œhadoopâ€ (itâ€™s a matter of issue):\r\n\r\n```\r\nmv hadoop-3.1.2 hadoop\r\n```\r\n\r\nMoving on we need to set some constants in our .bashrc file. That can be done by opening it with _vi_:\r\n\r\n```\r\nvi ~/.bashrc\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*_tItWFpxwnCX_rvKquM07Q.png)\r\n\r\nVi text editor\r\n\r\nInside _vi_, you just press â€œaâ€ (the append shortcut) on your keyboard and add the following to the bottom of the file:\r\n\r\n```\r\n**export** HADOOP\\_HOME=**/**home**/**hadoop**/**hadoop  \r\n**export** HADOOP\\_INSTALL=$HADOOP\\_HOME  \r\n**export** HADOOP\\_MAPRED\\_HOME=$HADOOP\\_HOME  \r\n**export** HADOOP\\_COMMON\\_HOME=$HADOOP\\_HOME  \r\n**export** HADOOP\\_HDFS\\_HOME=$HADOOP\\_HOME  \r\n**export** YARN\\_HOME=$HADOOP\\_HOME  \r\n**export** HADOOP\\_COMMON\\_LIB\\_NATIVE\\_DIR=$HADOOP\\_HOME**/**lib**/**native  \r\n**export** PATH=$PATH:$HADOOP\\_HOME**/**sbin:$HADOOP\\_HOME**/**bin\r\n```\r\n\r\n> Now, note that in my case the folder is just called â€œhadoopâ€, but that may not be the case if you didnâ€™t change it!\r\n\r\n![medium](https://miro.medium.com/max/1400/1*dRmuyOgvutNR-lNS5sjrSA.png)\r\n\r\nThen just press Esc and write â€œ:wqâ€ (for write and quit). That should save the file. However, to change the current environment, we have to use the command:\r\n\r\n```\r\nsource ~/.bashrc\r\n```\r\n\r\nTo make sure everything is set right we can use:\r\n\r\n```\r\nls $HADOOP\\_HOME\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*eLzatP494olkXGt22fFiWA.png)\r\n\r\nIn case you didnâ€™t get the same results as I did you should go back and review your \\~/.bashrc file.\r\n\r\n* * *\r\n\r\n3\\. Setting up Hadoop\r\n---------------------\r\n\r\nNow that we have hadoop on our machine we should configure it. This is where we use the Java that we installed in the beginning of this tutorial.\r\n\r\nFirst things first, we should navigate to the folder where all the configuration files should be by using:\r\n\r\n```\r\ncd $HADOOP\\_HOME/etc/hadoop\r\n```\r\n\r\nThe first file to edit is called â€œ hadoop-env.shâ€ and weâ€™re going to use _vi_ again:\r\n\r\n```\r\nvi hadoop-env.sh\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*4Tyakyfl_3Mrb-eTDnvjAQ.png)\r\n\r\nWe only need to add the line:\r\n\r\n```\r\nexport JAVA\\_HOME=/usr/lib/jvm/java-1.8.0-openjdk\r\n```\r\n\r\nIt should be irrevelant where to put it, as long as itâ€™s a new line. Then just write and quit _vi_. Finally, open and write for the following files:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*RP_pdHT4LiY_fGdFghqG1g.png)\r\n\r\ncore-site.xml\r\n\r\n![medium](https://miro.medium.com/max/1400/1*bQ24fh7I-BT328dkq2OF2A.png)\r\n\r\nhdfs-site.xml\r\n\r\n![medium](https://miro.medium.com/max/1400/1*imibbW3qTRzAlgRjej7MwA.png)\r\n\r\nmapred-site.xml\r\n\r\n![medium](https://miro.medium.com/max/1400/1*Aj5lWFMK5J80Qsf0TbZVXQ.png)\r\n\r\nyarn-site.xml\r\n\r\nWith that done we return to our default directory with the command â€œcdâ€:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*ymuX6elvFKG1NnRcfOsHRA.png)\r\n\r\nâ€œpwdâ€ means â€œprint working directoryâ€\r\n\r\n* * *\r\n\r\n4\\. Setting Up Multi-node\r\n-------------------------\r\n\r\nTo use a Multi-node setup we must define the nodes in our _hosts_ file, which can be achieved using _vi_ once more:\r\n\r\n```\r\nvi /etc/hosts\r\n```\r\n\r\nAll we need to add are the nodesâ€™ names and respective IP addresses. In my case Iâ€™m using three nodes, one  â€œmasterâ€ and two â€œworkersâ€:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*8Y0eVoZNZAXbOm4ObH5eEw.png)\r\n\r\nhosts file\r\n\r\nNow weâ€™re going to create those machines. To begin we have to clone the â€œmasterâ€ machine twice:\r\n\r\n![medium](https://miro.medium.com/max/870/1*H-i3f647yEyrCCvkoLmMxA.png)\r\n\r\nUsing the Right-Click, we select the â€œCloneâ€ option\r\n\r\n![medium](https://miro.medium.com/max/1400/1*0fPvXtuGSdgiRLg4QCUWUg.png)\r\n\r\nAfter choosing the name and folder to the new machine, VirtualBox will start cloning\r\n\r\nYou should now have three virtual machines. For them to be able to communicate with each other, weâ€™re going to open VirtualBoxâ€™s Network Settings:\r\n\r\n![medium](https://miro.medium.com/max/920/1*qPB5aGuC3qMwwI5Xl8fDpw.png)\r\n\r\nUsing Right-Click again, we select â€œSettingsâ€\r\n\r\nOn â€œNewtorkâ€, we select â€œAdapter 2\", enable and select Host-Only Adapter. Letâ€™s set â€œPromiscuous Modeâ€ to â€œAllow Allâ€ and be careful that the MAC Adresses are different from each other:\r\n\r\n![medium](https://miro.medium.com/max/1352/1*Jz7kT22mME9fDWy3Jv5Ckw.png)\r\n\r\nEach Virtual Machine should have a different hostname from the ones we defined in the _hosts_ file. Log in with the hadoop account directly for this part.\r\n\r\nThe rest is simpler than what weâ€™ve already done with _vi_:\r\n\r\n```\r\nvi /etc/hostname\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*FkwHGnvPTL3drmyQpyc3jw.png)\r\n\r\nTo further configure that, we have to use _nmtui_ like at the start of this tutorial:\r\n\r\n```\r\nnmtui\r\n```\r\n\r\nIn the new connection, â€œWired Connection 1â€ in my case, weâ€™ll simply set IPv4 to â€œManualâ€, press â€œShowâ€ and input the IP Address for the respective machine followed by â€œ/24â€. This is on my â€œmasterâ€ VM:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*G-0u8FbPK9JF2NSASppnzA.png)\r\n\r\nSimply press â€œOKâ€ and reboot. Rinse and repeat for each VM. We should now have a network between our machines:\r\n\r\n![medium](https://miro.medium.com/max/1400/1*4NlhytdbJTWclCTuO68K0w.png)\r\n\r\nNow letâ€™s inform Hadoop about the existing nodes. On our â€œmasterâ€ machine we should use the â€œhadoopâ€ user to edit the _workers_ file:\r\n\r\n```\r\nvi $HADOOP\\_HOME/etc/hadoop/workers\r\n```\r\n\r\nIn this file we need to write the machines that will do the work:\r\n\r\n```\r\nmaster  \r\nslave1  \r\nslave2\r\n```\r\n\r\n![medium](https://miro.medium.com/max/1400/1*O6yUMgICJyrJNmVE7qV9jg.png)\r\n\r\nFinally, with all the machines on, we start our cluster by using the following commands on the â€œmasterâ€ machine:\r\n\r\n```\r\n$HADOOP\\_HOME/etc/hadoop/start-dfs.sh  \r\n$HADOOP\\_HOME/etc/hadoop/start-yarn.sh\r\n```\r\n\r\nBut donâ€™t take my word for granted, open one of your â€œworkerâ€ machines and use the _jps_ command:\r\n\r\n```\r\njps\r\n```\r\n\r\n![medium](https://miro.medium.com/max/626/1*CP4SzVa3g5HLtQoBIkxrkw.png)\r\n\r\nIf you see â€œNodeManagerâ€ and â€œDataNodeâ€ there, your cluster is up and running ğŸ™‚\r\n","closed_by":{"login":"cfchenr","id":17366849,"node_id":"MDQ6VXNlcjE3MzY2ODQ5","avatar_url":"https://avatars.githubusercontent.com/u/17366849?v=4","gravatar_id":"","url":"https://api.github.com/users/cfchenr","html_url":"https://github.com/cfchenr","followers_url":"https://api.github.com/users/cfchenr/followers","following_url":"https://api.github.com/users/cfchenr/following{/other_user}","gists_url":"https://api.github.com/users/cfchenr/gists{/gist_id}","starred_url":"https://api.github.com/users/cfchenr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cfchenr/subscriptions","organizations_url":"https://api.github.com/users/cfchenr/orgs","repos_url":"https://api.github.com/users/cfchenr/repos","events_url":"https://api.github.com/users/cfchenr/events{/privacy}","received_events_url":"https://api.github.com/users/cfchenr/received_events","type":"User","site_admin":false},"performed_via_github_app":null},"relatedPosts":[]},"__N_SSG":true}